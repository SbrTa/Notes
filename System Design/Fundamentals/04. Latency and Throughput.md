# Latency and Throughput

### Latency
  - Latency refers to the amount of time it takes for data to be sent to its intended destination. 
  - It’s also referred to as the delay in moving data between two clients.
  - You may say that a second delay is no big deal, but that is not always the case. 
  - Let’s take a look at a real-world scenario of how latency can affect your network and browsing experience. 
    - For example, let’s see how latency affects online gaming.
    - With excellent latency (a low number) your actions in-game will be almost instant compared to your inputs.
    - With high latency, however, there might be a long delay between your clicks and what happens on the screen.
    - That might be fine if you are watching a movie or browsing the web. 
    - But for real-time interactions, low latency is a need. 
    - Otherwise, the experience is negatively affected.

### Throughput
  - Throughput is the amount of data that is successfully transmitted through a system in a certain amount of time, measured in bits per second (bps). 


### Throughput and Latency
  - The combination of throughput and latency is the best network performance metric.
  - By measuring both, you are able to know the amount of data that is being sent over a specific amount of time. 
  - They also need to work together if we want to achieve good results. 
  - It’s no good to have good throughput if latency is through the roof.
  - Yes, you’ll send a lot of data, but it will take too long to reach its destination. And even longer to get a reply.
  - Conversely, having ultra-low latency is no good if you can only send small chunks of data at a time. It will still take too long for all the information to travel to its destination.
