# Kafka Consumers
Applications that read data from Kafka topics are known as consumers. Applications integrate a Kafka client library to read from Apache Kafka. Excellent client libraries exist for almost all programming languages that are popular today including Python, Java, Go, and others.

Consumers can read from one or more partitions at a time in Apache Kafka, and data is read in order within each partition as shown below.

![image](https://github.com/SbrTa/Notes/assets/8649145/60dc9d12-5e9f-4ecb-8c3c-3fa77b6b30cc)

A consumer always reads data from a lower offset to a higher offset and cannot read data backwards (due to how Apache Kafka and clients are implemented).

If the consumer consumes data from more than one partition, the message order is not guaranteed across multiple partitions because they are consumed simultaneously, but the message read order is still guaranteed within each individual partition.

By default, Kafka consumers will only consume data that was produced after it first connected to Kafka. Which means that to read historical data in Kafka, one must specify it as an input to the command, as we will see in the practice section.

Kafka consumers are also known to implement a "pull model". This means that Kafka consumers must request data from Kafka brokers in order to get it (instead of having Kafka brokers continuously push data to consumers). This implementation was made so that consumers can control the speed at which the topics are being consumed.


### Kafka Message Deserializers
As we have seen before, the data sent by the Kafka producers is serialized. This means that the data received by the Kafka consumers must be correctly deserialized in order to be useful within your application. Data being consumed must be deserialized in the same format it was serialized in. For example:
- if the producer serialized a String using StringSerializer, the consumer must deserialize it using StringDeserializer
- if the producer serialized an Integer using IntegerSerializer, the consumer must deserialize it using IntegerDeserializer

![image](https://github.com/SbrTa/Notes/assets/8649145/c63c1e6f-0544-4df1-9370-3f381a301c7c)

The serialization and deserialization format of a topic must not change during a topic lifecycle. If you intend to switch a topic data format (for example from JSON to Avro), it is considered best practice to create a new topic and migrate your applications to leverage that new topic.

#### Poison Pills
Messages sent to a Kafka topic that do not respect the agreed-upon serialization format are called poison pills. They are not fun to deal with.

